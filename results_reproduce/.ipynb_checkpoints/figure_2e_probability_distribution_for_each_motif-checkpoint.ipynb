{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "072e7a4c-03b5-49c4-86d6-e2643f90b76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuyou/.conda/envs/TandemMod/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device= cpu\n",
      "loading data...\n",
      "predicting...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11634/438879052.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/wuyou/Projects/paper/model/m5C_median_mad.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroc_auc_MMAD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpr_auc_MMAD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreserved_ratio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0mfprs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtprs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11634/438879052.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, dataset, cut_off_threshold)\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdwell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbase_quality\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TandemMod/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11634/438879052.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, kmer, mean, std, intense, dwell, base_quality)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mout_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_n_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc_n_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TandemMod/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/TandemMod/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 775\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    776\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split as ts\n",
    "from sklearn.metrics import roc_curve,auc,roc_auc_score,precision_recall_curve\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from plotnine import *\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device=\",device)\n",
    "\n",
    "black = '#222222'\n",
    "gray = '#666666'\n",
    "red = '#FF3333'\n",
    "green = '#66CC00'\n",
    "blue = '#3333FF'\n",
    "purple = '#9933FF'\n",
    "orange = '#FF8000'\n",
    "yellow = '#FFFF33'\n",
    "\n",
    "\n",
    "\n",
    "class Config:\n",
    "\n",
    "    train_dir=\"m5C/feature/train/\"\n",
    "    test_dir=\"ELIGOS_C/feature/test/\"\n",
    "    #train_dir = \"data/motif/CTCAC/train/\"\n",
    "    #test_dir = \"data/motif/CTCAC/test/\"\n",
    "    batch_size = 500\n",
    "    learning_rate=0.00001\n",
    "    \n",
    "    \n",
    "kmer_encode_dic={'A': 0, \"C\": 1, \"G\": 2, \"T\": 3}  \n",
    "kmer_decode_dict ={0:\"A\", 1:\"C\", 2:\"G\", 3:\"T\"}\n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Bahdanau Attention mechanism module.\n",
    "\n",
    "    Args:\n",
    "        in_features (int): Number of input features.\n",
    "        hidden_units (int): Number of hidden units.\n",
    "        num_task (int): Number of tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self,in_features, hidden_units,num_task):\n",
    "        super(BahdanauAttention,self).__init__()\n",
    "        self.W1 = nn.Linear(in_features=in_features,out_features=hidden_units)\n",
    "        self.W2 = nn.Linear(in_features=in_features,out_features=hidden_units)\n",
    "        self.V = nn.Linear(in_features=hidden_units, out_features=num_task)\n",
    "\n",
    "    def forward(self, hidden_states, values):\n",
    "        hidden_with_time_axis = torch.unsqueeze(hidden_states,dim=1)\n",
    "\n",
    "        score  = self.V(nn.Tanh()(self.W1(values)+self.W2(hidden_with_time_axis)))\n",
    "        attention_weights = nn.Softmax(dim=1)(score)\n",
    "        values = torch.transpose(values,1,2)   # transpose to make it suitable for matrix multiplication\n",
    "        #print(attention_weights.shape,values.shape)\n",
    "        context_vector = torch.matmul(values,attention_weights)\n",
    "        context_vector = torch.transpose(context_vector,1,2)\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "class TandemMod(nn.Module):\n",
    "    def __init__(self,num_classes=2,vocab_zie=5, embedding_size=4,seq_len=5):\n",
    "        super(TandemMod,self).__init__()\n",
    "\n",
    "        self.seq_len=seq_len\n",
    "        self.embed = nn.Embedding(vocab_zie, embedding_size)\n",
    "\n",
    "        self.cnn_1d = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1,out_channels=64,kernel_size=7,stride=2,padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2,padding=1),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(in_channels=128,out_channels=128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2,padding=1),\n",
    "\n",
    "        )\n",
    "        self.lstm=nn.LSTM(input_size=128,hidden_size=128,batch_first=True,bidirectional=True)\n",
    "        self.attention=BahdanauAttention(in_features=256,hidden_units=10,num_task=1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=1536,out_features=1536),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1536, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512,out_features=2)\n",
    "        )\n",
    "\n",
    "        self.lstm_seq=nn.LSTM(input_size=4+5,hidden_size=128,batch_first=True,bidirectional=True)   #embedding_size+feature_num\n",
    "\n",
    "\n",
    "    def seq_to_digit(self,seq):\n",
    "        return torch.Tensor([{'A': 0, \"C\": 1, \"G\": 2, \"T\": 3}[i] for i in list(seq)]).long()\n",
    "\n",
    "\n",
    "    def forward(self,x,kmer,mean,std,intense,dwell,base_quality):\n",
    "        kmer_embedded=self.embed(kmer)\n",
    "        mean = torch.reshape(mean, (-1, self.seq_len, 1)).float()\n",
    "        std = torch.reshape(std, (-1, self.seq_len, 1)).float()\n",
    "        intense = torch.reshape(intense, (-1, self.seq_len, 1)).float()\n",
    "        dwell = torch.reshape(dwell, (-1, self.seq_len, 1)).float()\n",
    "        base_quality = torch.reshape(base_quality, (-1, self.seq_len, 1)).float()\n",
    "        \n",
    "        out_seq=torch.cat((kmer_embedded,mean,std,intense,dwell,base_quality),2)\n",
    "\n",
    "\n",
    "        out_seq,(h_n_seq,c_n_seq)=self.lstm_seq(out_seq)\n",
    "\n",
    "        x = self.cnn_1d(x)\n",
    "\n",
    "        batch_size, features, seq_len = x.size()\n",
    "        x = x.view(batch_size, seq_len, features)  # parepare input for LSTM\n",
    "\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "\n",
    "        h_n = h_n.view(batch_size, output.size()[-1])  # pareprae input for Attention\n",
    "        context_vector, attention_weights = self.attention(h_n, output)  # Attention (batch_size, num_task, unit)\n",
    "\n",
    "\n",
    "        out=torch.cat((out_seq[:,0,:],out_seq[:,1,:],out_seq[:,2,:],out_seq[:,3,:],out_seq[:,4,:],context_vector[:,0,:]),1)\n",
    "        #out=context_vector[:,0,:]\n",
    "        out.view(out.size()[0],1,out.size()[1])\n",
    "        x=self.fc(out)\n",
    "        #x.view(x.size()[0], 1, x.size()[1])\n",
    "        return x\n",
    "\n",
    "\n",
    "class NN(TandemMod):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the NN class.\n",
    "        Inherits from the TandemMod class.\n",
    "        \"\"\"\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "################median mad####################################################    \n",
    "x_test_median_mad,y_test_median_mad=[],[]\n",
    "f=open(\"/home/wuyou/Projects/paper/ELIGOS_normalC/feature/median_mad/ELIGOS_normalC\")\n",
    "for i,line in enumerate(f):\n",
    "    if i>2e3:\n",
    "        break\n",
    "    line=line.rstrip()\n",
    "    items=line.split(\"\\t\")\n",
    "\n",
    "    signals=\"|\".join(items[9:14]).split(\"|\")\n",
    "    signal=np.array([float(signal) for signal in signals])\n",
    "    #signal=(signal-np.mean(signal))/np.std(signal)\n",
    "    kmer = items[3]\n",
    "    kmer=np.array([kmer_encode_dic[base] for base in kmer])\n",
    "    mean = np.array([float(item) for item in items[4].split(\"|\")])\n",
    "    std = np.array([float(item) for item in items[5].split(\"|\")])\n",
    "    intense = np.array([float(item) for item in items[6].split(\"|\")])\n",
    "    dwell = np.array([float(item) for item in items[7].split(\"|\")])/200\n",
    "    base_quality = np.array([float(item) for item in items[8].split(\"|\")])/40\n",
    "    x=[signal, kmer, mean, std, intense, dwell,base_quality]\n",
    "    x_test_median_mad.append(x)\n",
    "    y_test_median_mad.append(0)\n",
    "f.close()\n",
    "\n",
    "f=open(\"/home/wuyou/Projects/paper/ELIGOS_m5C/feature/median_mad/ELIGOS_m5C\")\n",
    "for i,line in enumerate(f):\n",
    "    if i>2e3:\n",
    "        break\n",
    "    line=line.rstrip()\n",
    "    items=line.split(\"\\t\")\n",
    "\n",
    "    signals=\"|\".join(items[9:14]).split(\"|\")\n",
    "    signal=np.array([float(signal) for signal in signals])\n",
    "    #signal=(signal-np.mean(signal))/np.std(signal)\n",
    "    kmer = items[3]\n",
    "    kmer=np.array([kmer_encode_dic[base] for base in kmer])\n",
    "    mean = np.array([float(item) for item in items[4].split(\"|\")])\n",
    "    std = np.array([float(item) for item in items[5].split(\"|\")])\n",
    "    intense = np.array([float(item) for item in items[6].split(\"|\")])\n",
    "    dwell = np.array([float(item) for item in items[7].split(\"|\")])/200\n",
    "    base_quality = np.array([float(item) for item in items[8].split(\"|\")])/40\n",
    "    x=[signal, kmer, mean, std, intense, dwell,base_quality]\n",
    "    x_test_median_mad.append(x)\n",
    "    y_test_median_mad.append(1)\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset class.\n",
    "\n",
    "    Args:\n",
    "        x (list or numpy array): Input data.\n",
    "        y (list or numpy array): Target data.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,x,y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index],self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "\n",
    "def make_weights_for_balanced_classes(images, nclasses):\n",
    "    \"\"\"\n",
    "    Computes weights for balancing classes in a dataset.\n",
    "\n",
    "    Args:\n",
    "        images (list): List of images.\n",
    "        nclasses (int): Number of classes.\n",
    "\n",
    "    Returns:\n",
    "        list: List of weights.\n",
    "\n",
    "    \"\"\"\n",
    "    count = [0] * nclasses\n",
    "    for item in images:\n",
    "        count[item[1]] += 1\n",
    "    weight_per_class = [0.] * nclasses\n",
    "    N = float(sum(count))\n",
    "    for i in range(nclasses):\n",
    "        weight_per_class[i] = N/float(count[i])\n",
    "    weight = [0] * len(images)\n",
    "    for idx, val in enumerate(images):\n",
    "        weight[idx] = weight_per_class[val[1]]\n",
    "    return weight\n",
    "\n",
    "\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "class CustomWeightedRandomSampler(WeightedRandomSampler):\n",
    "    \"\"\"\n",
    "    Custom implementation of WeightedRandomSampler.\n",
    "    WeightedRandomSampler except allows for more than 2^24 samples to be sampled\n",
    "    Args:\n",
    "        *args: Variable length argument list.\n",
    "        **kwargs: Arbitrary keyword arguments.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __iter__(self):\n",
    "        rand_tensor = np.random.choice(range(0, len(self.weights)),\n",
    "                                       size=self.num_samples,\n",
    "                                       p=self.weights.numpy() / torch.sum(self.weights).numpy(),\n",
    "                                       replace=self.replacement)\n",
    "        rand_tensor = torch.from_numpy(rand_tensor)\n",
    "        return iter(rand_tensor.tolist())\n",
    "\n",
    "print(\"loading data...\")\n",
    "\n",
    "model = TandemMod(num_classes=2,vocab_zie=5, embedding_size=4,seq_len=5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()#.to(device)\n",
    "#predict_result=open(\"rice/results/WT_precit_results.tsv\",\"w\")\n",
    "\n",
    "def predict(model,dataset,cut_off_threshold):\n",
    "    \"\"\"\n",
    "    Predicts the output of the model on the given dataset.\n",
    "\n",
    "    Parameters:\n",
    "        model (nn.Module): The trained model to use for prediction.\n",
    "        dataset (torch.utils.data.Dataset): The dataset to predict on.\n",
    "\n",
    "    Returns:\n",
    "        fpr (array): False positive rates.\n",
    "        tpr (array): True positive rates.\n",
    "        precision (array): Precision values.\n",
    "        recall (array): Recall values.\n",
    "        roc_auc (float): Area under the ROC curve.\n",
    "        pr_auc (float): Area under the precision-recall curve.\n",
    "    \"\"\"\n",
    "\n",
    "    dataloader=torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                           batch_size=2000, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=36,\n",
    "                                           pin_memory=True)\n",
    "\n",
    "    try:\n",
    "\n",
    "        test_acc = 0.\n",
    "        y_test = []\n",
    "        y_pred = []\n",
    "        label_dict={0:\"m5C\",1:\"C\"}\n",
    "\n",
    "        for i,(batch_x, batch_y) in enumerate(dataloader):\n",
    "\n",
    "            signal, kmer, mean, std, intense, dwell,base_quality = batch_x\n",
    "            signal= Variable(signal.to(device)).to(torch.float32)\n",
    "\n",
    "            kmer = Variable(kmer.to(device)).to(torch.long)\n",
    "            mean = Variable(mean.to(device)).to(torch.float32)\n",
    "            std = Variable(std.to(device)).to(torch.float32)\n",
    "            intense = Variable(intense.to(device)).to(torch.float32)\n",
    "            dwell = Variable(dwell.to(device)).to(torch.float32)\n",
    "            base_quality = Variable(base_quality.to(device)).to(torch.float32)\n",
    "            batch_size, features = signal.size()\n",
    "            signal = signal.view(batch_size, 1, features)\n",
    "\n",
    "            out = model(signal, kmer, mean, std, intense, dwell,base_quality )\n",
    "            batch_size, out_channels = out.size()\n",
    "\n",
    "            out = out.view(batch_size, out_channels)\n",
    "            pred = torch.max(out, 1)[1].numpy()\n",
    "\n",
    "            out=torch.softmax(out,dim=1)\n",
    "            probabilities=out.detach().numpy()[:,1]\n",
    "            batch_y=batch_y.detach().numpy()\n",
    "            #print(probabilities)\n",
    "            \n",
    "            \n",
    "            selected_batch_y=[]\n",
    "            selected_probabilities=[]\n",
    "            for j in range(len(batch_y)):\n",
    "                if probabilities[j]<cut_off_threshold[0] or probabilities[j]>cut_off_threshold[1]:\n",
    "                    selected_batch_y.append(batch_y[j])\n",
    "                    selected_probabilities.append(probabilities[j])\n",
    "            \n",
    "            print(\"Probability cutoff:\",cut_off_threshold[0],cut_off_threshold[1],\"\\tPreserved sites:\",len(selected_batch_y))\n",
    "            fpr,tpr,thersholds=roc_curve(selected_batch_y,selected_probabilities)\n",
    "            precision,recall,thersholds=precision_recall_curve(selected_batch_y,selected_probabilities)\n",
    "            \n",
    "            roc_auc=auc(fpr,tpr)\n",
    "            pr_auc=auc(recall,precision)\n",
    "            \n",
    "            return fpr,tpr,precision,recall,roc_auc,pr_auc,len(selected_batch_y)/len(batch_y),probabilities,batch_y\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "\n",
    "def decode(t):\n",
    "    motifs=[]\n",
    "    for item in t:\n",
    "        motifs.append(\"\".join([kmer_decode_dict(base) for base in item]))\n",
    "    return motifs\n",
    "\n",
    "\n",
    "def predict_motif(model,dataset,cut_off_threshold):\n",
    "    \"\"\"\n",
    "    Predicts the output of the model on the given dataset.\n",
    "\n",
    "    Parameters:\n",
    "        model (nn.Module): The trained model to use for prediction.\n",
    "        dataset (torch.utils.data.Dataset): The dataset to predict on.\n",
    "\n",
    "    Returns:\n",
    "        fpr (array): False positive rates.\n",
    "        tpr (array): True positive rates.\n",
    "        precision (array): Precision values.\n",
    "        recall (array): Recall values.\n",
    "        roc_auc (float): Area under the ROC curve.\n",
    "        pr_auc (float): Area under the precision-recall curve.\n",
    "    \"\"\"\n",
    "\n",
    "    dataloader=torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                           batch_size=2000, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=36,\n",
    "                                           pin_memory=True)\n",
    "\n",
    "    try:\n",
    "\n",
    "        test_acc = 0.\n",
    "        y_test = []\n",
    "        y_pred = []\n",
    "        label_dict={0:\"m5C\",1:\"C\"}\n",
    "        labels=[]\n",
    "        motifs=[]\n",
    "        P=[]\n",
    "        for i,(batch_x, batch_y) in enumerate(dataloader):\n",
    "\n",
    "            signal, kmer, mean, std, intense, dwell,base_quality = batch_x\n",
    "            signal= Variable(signal.to(device)).to(torch.float32)\n",
    "\n",
    "            kmer = Variable(kmer.to(device)).to(torch.long)\n",
    "            mean = Variable(mean.to(device)).to(torch.float32)\n",
    "            std = Variable(std.to(device)).to(torch.float32)\n",
    "            intense = Variable(intense.to(device)).to(torch.float32)\n",
    "            dwell = Variable(dwell.to(device)).to(torch.float32)\n",
    "            base_quality = Variable(base_quality.to(device)).to(torch.float32)\n",
    "            batch_size, features = signal.size()\n",
    "            signal = signal.view(batch_size, 1, features)\n",
    "\n",
    "            out = model(signal, kmer, mean, std, intense, dwell,base_quality )\n",
    "            batch_size, out_channels = out.size()\n",
    "\n",
    "            out = out.view(batch_size, out_channels)\n",
    "            pred = torch.max(out, 1)[1].numpy()\n",
    "\n",
    "            out=torch.softmax(out,dim=1)\n",
    "            probabilities=out.detach().numpy()[:,1]\n",
    "            batch_y=batch_y.detach().numpy()\n",
    "            #print(probabilities)\n",
    "            \n",
    "            \n",
    "            selected_batch_y=[]\n",
    "            selected_probabilities=[]\n",
    "            for j in range(len(batch_y)):\n",
    "                if probabilities[j]<cut_off_threshold[0] or probabilities[j]>cut_off_threshold[1]:\n",
    "                    selected_batch_y.append(batch_y[j])\n",
    "                    selected_probabilities.append(probabilities[j])\n",
    "            \n",
    "            print(\"Probability cutoff:\",cut_off_threshold[0],cut_off_threshold[1],\"\\tPreserved sites:\",len(selected_batch_y))\n",
    "            fpr,tpr,thersholds=roc_curve(selected_batch_y,selected_probabilities)\n",
    "            precision,recall,thersholds=precision_recall_curve(selected_batch_y,selected_probabilities)\n",
    "            \n",
    "            roc_auc=auc(fpr,tpr)\n",
    "            pr_auc=auc(recall,precision)\n",
    "            \n",
    "            P.extend(list(probabilities))\n",
    "            labels.extend(list(batch_y))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            print(432,kmer)\n",
    "            motifs.extend(kmer)\n",
    "\n",
    "        return P,labels,motifs\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        traceback.print_exc()\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    #parser = argparse.ArgumentParser(description='Extract feature from signal.')\n",
    "    #parser.add_argument('-feature', default='BaseCalled_template',help='Basecall subgroup Nanoraw resquiggle into. Default is BaseCalled_template')\n",
    "    #args = parser.parse_args()\n",
    "  \n",
    "    \n",
    "    fprs,tprs,precisions,recalls,normalization_roc,normalization_pr,preserved_ratio_list=[],[],[],[],[],[],[]\n",
    "    \n",
    "    dataset=MyDataset(x_test_median_mad,y_test_median_mad)\n",
    "\n",
    "    print(\"predicting...\")\n",
    "    \n",
    "    model= torch.load('/home/wuyou/Projects/paper/model/m5C_median_mad.pkl')\n",
    "    fpr,tpr,precision,recall,roc_auc_MMAD,pr_auc_MMAD,preserved_ratio,probabilities,_=predict(model,dataset,[0.5,0.5])\n",
    "    fprs.extend(fpr)\n",
    "    tprs.extend(tpr)\n",
    "    precisions.extend(precision)\n",
    "    recalls.extend(recall)\n",
    "    preserved_ratio_list.append(preserved_ratio)\n",
    "    normalization_roc.extend([\"0.5 0.5 AUC %.2f\" %roc_auc_MMAD]*len(fpr))\n",
    "    normalization_pr.extend([\"0.5 0.5 AUC %.2f\" %pr_auc_MMAD]*len(precision))\n",
    "    \n",
    "    \n",
    "    fpr,tpr,precision,recall,roc_auc_MMAD,pr_auc_MMAD,preserved_ratio,probabilities,_=predict(model,dataset,[0.4,0.6])\n",
    "    fprs.extend(fpr)\n",
    "    tprs.extend(tpr)\n",
    "    precisions.extend(precision)\n",
    "    recalls.extend(recall)\n",
    "    preserved_ratio_list.append(preserved_ratio)\n",
    "    normalization_roc.extend([\"0.4 0.6 AUC %.2f\" %roc_auc_MMAD]*len(fpr))\n",
    "    normalization_pr.extend([\"0.4 0.6 AUC %.2f\" %pr_auc_MMAD]*len(precision))\n",
    "    \n",
    "    fpr,tpr,precision,recall,roc_auc_MMAD,pr_auc_MMA,preserved_ratio,probabilities,_=predict(model,dataset,[0.3,0.7])\n",
    "    fprs.extend(fpr)\n",
    "    tprs.extend(tpr)\n",
    "    precisions.extend(precision)\n",
    "    recalls.extend(recall)\n",
    "    preserved_ratio_list.append(preserved_ratio)\n",
    "    normalization_roc.extend([\"0.3 0.7 AUC %.2f\" %roc_auc_MMAD]*len(fpr))\n",
    "    normalization_pr.extend([\"0.3 0.7 AUC %.2f\" %pr_auc_MMAD]*len(precision))\n",
    "    \n",
    "    fpr,tpr,precision,recall,roc_auc_MMAD,pr_auc_MMAD,preserved_ratio,probabilities,_=predict(model,dataset,[0.2,0.8])\n",
    "    fprs.extend(fpr)\n",
    "    tprs.extend(tpr)\n",
    "    precisions.extend(precision)\n",
    "    recalls.extend(recall)\n",
    "    preserved_ratio_list.append(preserved_ratio)\n",
    "    normalization_roc.extend([\"0.2 0.8 AUC %.2f\" %roc_auc_MMAD]*len(fpr))\n",
    "    normalization_pr.extend([\"0.2 0.8 AUC %.2f\" %pr_auc_MMAD]*len(precision))\n",
    "    \n",
    "    fpr,tpr,precision,recall,roc_auc_MMAD,pr_auc_MMAD,preserved_ratio,probabilities,_=predict(model,dataset,[0.1,0.9])\n",
    "    fprs.extend(fpr)\n",
    "    tprs.extend(tpr)\n",
    "    precisions.extend(precision)\n",
    "    recalls.extend(recall)\n",
    "    preserved_ratio_list.append(preserved_ratio)\n",
    "    normalization_roc.extend([\"0.1 0.9 AUC %.2f\" %roc_auc_MMAD]*len(fpr))\n",
    "    normalization_pr.extend([\"0.1 0.9 AUC %.2f\" %pr_auc_MMAD]*len(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d364288a-cc07-4a95-8f31-a5d62fea47b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability cutoff: 0.5 0.5 \tPreserved sites: 2000\n",
      "432 tensor([[1, 1, 1, 2, 2],\n",
      "        [1, 0, 1, 0, 3],\n",
      "        [3, 2, 1, 0, 1],\n",
      "        ...,\n",
      "        [3, 3, 1, 1, 3],\n",
      "        [2, 2, 1, 2, 1],\n",
      "        [3, 3, 1, 0, 2]])\n",
      "Probability cutoff: 0.5 0.5 \tPreserved sites: 2000\n",
      "432 tensor([[0, 0, 1, 1, 0],\n",
      "        [3, 2, 1, 0, 3],\n",
      "        [3, 2, 1, 1, 0],\n",
      "        ...,\n",
      "        [1, 3, 1, 0, 3],\n",
      "        [2, 2, 1, 2, 1],\n",
      "        [0, 3, 1, 1, 2]])\n",
      "Probability cutoff: 0.5 0.5 \tPreserved sites: 2\n",
      "432 tensor([[1, 1, 1, 3, 0],\n",
      "        [2, 0, 1, 1, 1]])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'probabilities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11634/1438355604.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#fpr,tpr,precision,recall,roc_auc_MMAD,pr_auc_MMAD,preserved_ratio,probabilities,labels=predict(model,dataset,[0.5,0.5])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProbabilities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdata_C\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'probabilities' is not defined"
     ]
    }
   ],
   "source": [
    "model= torch.load('/home/wuyou/Projects/paper/model/m5C_median_mad.pkl')\n",
    "P,labels,motifs=predict_motif(model,dataset,[0.5,0.5])\n",
    "#fpr,tpr,precision,recall,roc_auc_MMAD,pr_auc_MMAD,preserved_ratio,probabilities,labels=predict(model,dataset,[0.5,0.5])\n",
    "\n",
    "data=pd.DataFrame(dict(Probabilities=probabilities,label=labels)) \n",
    "\n",
    "data_C=data[data[\"label\"]==0]\n",
    "print(data)\n",
    "#data.to_csv(\"data/density_of_reads_probablilities_m5C_on_ELIGOS.csv\")\n",
    "p1 = (ggplot()\n",
    "        #+geom_bar(data,aes(x=\"Probabilities\",y = \"Proportion\"),stat=\"identity\",width=0.6)\n",
    "        +geom_density(data_C,aes(x=\"Probabilities\",fill=\"black\",color=\"black\"),alpha=0.1,show_legend=False)\n",
    "        +theme(panel_background=element_rect(fill=gray, alpha=0),\n",
    "            panel_grid_major=element_line(size=0.3, alpha=0,color=black),\n",
    "            panel_grid_minor=element_line(size=0.3, alpha=0,color=black),\n",
    "            panel_border=element_rect(color=black, size=1),\n",
    "            axis_text=element_text(size=6,family=\"Arial\",color=\"black\"),\n",
    "            axis_title_x=element_text(size=6,family=\"Arial\",color=\"black\"),\n",
    "            axis_title_y=element_text(size=6,family=\"Arial\",color=\"black\"),\n",
    "            plot_title=element_text(margin={'b': 1, 'r': 0, 'units': 'pt'},size=6,family=\"Arial\",color=\"black\",hjust=0.5),\n",
    "            #axis_text_x=element_text(rotation=45, hjust=0.5),\n",
    "            figure_size=[1.52,1.53],\n",
    "            #legend_title = element_text(size=6), #change legend title font size\n",
    "            #legend_text = element_text(size=6),\n",
    "            #legend_background=element_rect(size=0.5,alpha=0),\n",
    "            legend_position=(0.60,0.4),\n",
    "            #legend_key_size=4   #change legend text font size\n",
    "              ) \n",
    "        +labs(x = \"Probabilities\", y =\"Density\")\n",
    "        #guides(color = guide_legend(title = \"Probability cutoff\"))\n",
    "      +ggtitle(\"Probability distribution of C\")\n",
    "\n",
    ")\n",
    "print(p1)\n",
    "p1.save(\"figure/figure_2e_probabilities_distribution_of_C_on_ELIGOS.pdf\")\n",
    "\n",
    "data_m5C=data[data[\"label\"]==1]\n",
    "print(data)\n",
    "#data.to_csv(\"data/density_of_reads_probablilities_m5C_on_ELIGOS.csv\")\n",
    "p1 = (ggplot()\n",
    "        #+geom_bar(data,aes(x=\"Probabilities\",y = \"Proportion\"),stat=\"identity\",width=0.6)\n",
    "        +geom_density(data_m5C,aes(x=\"Probabilities\",fill=\"black\",color=\"black\"),alpha=0.1,show_legend=False)\n",
    "        +theme(panel_background=element_rect(fill=gray, alpha=0),\n",
    "            panel_grid_major=element_line(size=0.3, alpha=0,color=black),\n",
    "            panel_grid_minor=element_line(size=0.3, alpha=0,color=black),\n",
    "            panel_border=element_rect(color=black, size=1),\n",
    "            axis_text=element_text(size=6,family=\"Arial\",color=\"black\"),\n",
    "            axis_title_x=element_text(size=6,family=\"Arial\",color=\"black\"),\n",
    "            axis_title_y=element_text(size=6,family=\"Arial\",color=\"black\"),\n",
    "            plot_title=element_text(margin={'b': 1, 'r': 0, 'units': 'pt'},size=6,family=\"Arial\",color=\"black\",hjust=0.5),\n",
    "            #axis_text_x=element_text(rotation=45, hjust=0.5),\n",
    "            figure_size=[1.52,1.53],\n",
    "            #legend_title = element_text(size=6), #change legend title font size\n",
    "            #legend_text = element_text(size=6),\n",
    "            #legend_background=element_rect(size=0.5,alpha=0),\n",
    "            legend_position=(0.60,0.4),\n",
    "            #legend_key_size=4   #change legend text font size\n",
    "              ) \n",
    "        +labs(x = \"Probabilities\", y =\"Density\")\n",
    "        #guides(color = guide_legend(title = \"Probability cutoff\"))\n",
    "      +ggtitle(\"Probability distribution of m5C\")\n",
    "\n",
    ")\n",
    "print(p1)\n",
    "p1.save(\"figure/figure_2e_probabilities_distribution_of_m5C_on_ELIGOS.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d32a8e0-55c1-4bc8-8a47-38381dbafec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0446707f-de2b-4b02-8b75-cab006f30ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probabilities</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.959090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.019096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.102722</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.493073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.000514</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.007671</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.010117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.151000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1006 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Probabilities  label\n",
       "0          0.000239      0\n",
       "4          0.000006      0\n",
       "6          0.959090      0\n",
       "8          0.019096      0\n",
       "9          0.102722      0\n",
       "...             ...    ...\n",
       "1993       0.493073      0\n",
       "1994       0.000514      0\n",
       "1995       0.007671      0\n",
       "1998       0.010117      0\n",
       "1999       0.151000      0\n",
       "\n",
       "[1006 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe8249-c6e7-4bfb-9618-024c7706c8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
