{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "defc76af-f385-4cc0-b755-f4adf2359ebd",
   "metadata": {},
   "source": [
    "### Compare IVET with curlcake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d0955e-c01f-4a52-af9d-bab4b4e52ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split as ts\n",
    "from sklearn.metrics import roc_curve,auc,roc_auc_score,precision_recall_curve\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from plotnine import *\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device=\",device)\n",
    "\n",
    "black = '#222222'\n",
    "gray = '#666666'\n",
    "red = '#FF3333'\n",
    "green = '#66CC00'\n",
    "blue = '#3333FF'\n",
    "purple = '#9933FF'\n",
    "orange = '#FF8000'\n",
    "yellow = '#FFFF33'\n",
    "\n",
    "\n",
    "class Config:\n",
    "\n",
    "    train_dir=\"m5C/feature/train/\"\n",
    "    test_dir=\"ELIGOS_C/feature/test/\"\n",
    "    #train_dir = \"data/motif/CTCAC/train/\"\n",
    "    #test_dir = \"data/motif/CTCAC/test/\"\n",
    "    batch_size = 500\n",
    "    learning_rate=0.00001\n",
    "    \n",
    "    \n",
    "kmer_encode_dic={'A': 0, \"C\": 1, \"G\": 2, \"T\": 3}   \n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Bahdanau Attention mechanism module.\n",
    "\n",
    "    Args:\n",
    "        in_features (int): Number of input features.\n",
    "        hidden_units (int): Number of hidden units.\n",
    "        num_task (int): Number of tasks.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,in_features, hidden_units,num_task):\n",
    "        super(BahdanauAttention,self).__init__()\n",
    "        self.W1 = nn.Linear(in_features=in_features,out_features=hidden_units)\n",
    "        self.W2 = nn.Linear(in_features=in_features,out_features=hidden_units)\n",
    "        self.V = nn.Linear(in_features=hidden_units, out_features=num_task)\n",
    "\n",
    "    def forward(self, hidden_states, values):\n",
    "        \"\"\"\n",
    "        Forward pass of the Bahdanau Attention mechanism.\n",
    "\n",
    "        Args:\n",
    "            hidden_states (torch.Tensor): Hidden states tensor.\n",
    "            values (torch.Tensor): Values tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Context vector.\n",
    "            torch.Tensor: Attention weights.\n",
    "\n",
    "        \"\"\"\n",
    "        hidden_with_time_axis = torch.unsqueeze(hidden_states,dim=1)\n",
    "\n",
    "        score  = self.V(nn.Tanh()(self.W1(values)+self.W2(hidden_with_time_axis)))\n",
    "        attention_weights = nn.Softmax(dim=1)(score)\n",
    "        values = torch.transpose(values,1,2)   # transpose to make it suitable for matrix multiplication\n",
    "        #print(attention_weights.shape,values.shape)\n",
    "        context_vector = torch.matmul(values,attention_weights)\n",
    "        context_vector = torch.transpose(context_vector,1,2)\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "class TandemMod(nn.Module):\n",
    "    def __init__(self,num_classes=2,vocab_zie=5, embedding_size=4,seq_len=5):\n",
    "        super(TandemMod,self).__init__()\n",
    "\n",
    "        self.seq_len=seq_len\n",
    "        self.embed = nn.Embedding(vocab_zie, embedding_size)\n",
    "\n",
    "        self.cnn_1d = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1,out_channels=64,kernel_size=7,stride=2,padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2,padding=1),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(in_channels=128,out_channels=128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2,padding=1),\n",
    "\n",
    "        )\n",
    "        self.lstm=nn.LSTM(input_size=128,hidden_size=128,batch_first=True,bidirectional=True)\n",
    "        self.attention=BahdanauAttention(in_features=256,hidden_units=10,num_task=1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=1536,out_features=1536),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1536, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512,out_features=2)\n",
    "        )\n",
    "\n",
    "        self.lstm_seq=nn.LSTM(input_size=4+5,hidden_size=128,batch_first=True,bidirectional=True)   #embedding_size+feature_num\n",
    "\n",
    "\n",
    "    def seq_to_digit(self,seq):\n",
    "        return torch.Tensor([{'A': 0, \"C\": 1, \"G\": 2, \"T\": 3}[i] for i in list(seq)]).long()\n",
    "\n",
    "\n",
    "    def forward(self,x,kmer,mean,std,intense,dwell,base_quality):\n",
    "        kmer_embedded=self.embed(kmer)\n",
    "        mean = torch.reshape(mean, (-1, self.seq_len, 1)).float()\n",
    "        std = torch.reshape(std, (-1, self.seq_len, 1)).float()\n",
    "        intense = torch.reshape(intense, (-1, self.seq_len, 1)).float()\n",
    "        dwell = torch.reshape(dwell, (-1, self.seq_len, 1)).float()\n",
    "        base_quality = torch.reshape(base_quality, (-1, self.seq_len, 1)).float()\n",
    "        \n",
    "        out_seq=torch.cat((kmer_embedded,mean,std,intense,dwell,base_quality),2)\n",
    "\n",
    "\n",
    "        out_seq,(h_n_seq,c_n_seq)=self.lstm_seq(out_seq)\n",
    "\n",
    "        x = self.cnn_1d(x)\n",
    "\n",
    "        batch_size, features, seq_len = x.size()\n",
    "        x = x.view(batch_size, seq_len, features)  # parepare input for LSTM\n",
    "\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "\n",
    "        h_n = h_n.view(batch_size, output.size()[-1])  # pareprae input for Attention\n",
    "        context_vector, attention_weights = self.attention(h_n, output)  # Attention (batch_size, num_task, unit)\n",
    "\n",
    "\n",
    "        out=torch.cat((out_seq[:,0,:],out_seq[:,1,:],out_seq[:,2,:],out_seq[:,3,:],out_seq[:,4,:],context_vector[:,0,:]),1)\n",
    "        #out=context_vector[:,0,:]\n",
    "        out.view(out.size()[0],1,out.size()[1])\n",
    "        x=self.fc(out)\n",
    "        #x.view(x.size()[0], 1, x.size()[1])\n",
    "        return x\n",
    "\n",
    "\n",
    "class NN(TandemMod):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the NN class.\n",
    "        Inherits from the TandemMod class.\n",
    "        \"\"\"\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        \n",
    "################median mad####################################################    \n",
    "x_test_median_mad,y_test_median_mad=[],[]\n",
    "f=open(\"/home/wuyou/Projects/paper/ELIGOS_normalC/feature/median_mad/unmod\")\n",
    "for i,line in enumerate(f):\n",
    "    if i>2e3:\n",
    "        break\n",
    "\n",
    "    line=line.rstrip()\n",
    "    items=line.split(\"\\t\")\n",
    "    contig=items[1]\n",
    "\n",
    "    \n",
    "    signals=\"|\".join(items[9:14]).split(\"|\")\n",
    "    signal=np.array([float(signal) for signal in signals])\n",
    "    #signal=(signal-np.mean(signal))/np.std(signal)\n",
    "    kmer = items[3]\n",
    "    kmer=np.array([kmer_encode_dic[base] for base in kmer])\n",
    "    mean = np.array([float(item) for item in items[4].split(\"|\")])\n",
    "    std = np.array([float(item) for item in items[5].split(\"|\")])\n",
    "    intense = np.array([float(item) for item in items[6].split(\"|\")])\n",
    "    dwell = np.array([float(item) for item in items[7].split(\"|\")])/200\n",
    "    base_quality = np.array([float(item) for item in items[8].split(\"|\")])/40\n",
    "    x=[signal, kmer, mean, std, intense, dwell,base_quality]\n",
    "    x_test_median_mad.append(x)\n",
    "    y_test_median_mad.append(0)\n",
    "f.close()\n",
    "\n",
    "f=open(\"/home/wuyou/Projects/paper/ELIGOS_m5C/feature/median_mad/mod\")\n",
    "for i,line in enumerate(f):\n",
    "    if i>2e3:\n",
    "        break\n",
    "        pass\n",
    "    line=line.rstrip()\n",
    "    items=line.split(\"\\t\")\n",
    "    \n",
    "    contig=items[1]\n",
    "\n",
    "        \n",
    "    signals=\"|\".join(items[9:14]).split(\"|\")\n",
    "    signal=np.array([float(signal) for signal in signals])\n",
    "    #signal=(signal-np.mean(signal))/np.std(signal)\n",
    "    kmer = items[3]\n",
    "    kmer=np.array([kmer_encode_dic[base] for base in kmer])\n",
    "    mean = np.array([float(item) for item in items[4].split(\"|\")])\n",
    "    std = np.array([float(item) for item in items[5].split(\"|\")])\n",
    "    intense = np.array([float(item) for item in items[6].split(\"|\")])\n",
    "    dwell = np.array([float(item) for item in items[7].split(\"|\")])/200\n",
    "    base_quality = np.array([float(item) for item in items[8].split(\"|\")])/40\n",
    "    x=[signal, kmer, mean, std, intense, dwell,base_quality]\n",
    "    x_test_median_mad.append(x)\n",
    "    y_test_median_mad.append(1)\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset class.\n",
    "\n",
    "    Args:\n",
    "        x (list or numpy array): Input data.\n",
    "        y (list or numpy array): Target data.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,x,y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index],self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "\n",
    "def make_weights_for_balanced_classes(images, nclasses):\n",
    "    \"\"\"\n",
    "    Computes weights for balancing classes in a dataset.\n",
    "\n",
    "    Args:\n",
    "        images (list): List of images.\n",
    "        nclasses (int): Number of classes.\n",
    "\n",
    "    Returns:\n",
    "        list: List of weights.\n",
    "\n",
    "    \"\"\"\n",
    "    count = [0] * nclasses\n",
    "    for item in images:\n",
    "        count[item[1]] += 1\n",
    "    weight_per_class = [0.] * nclasses\n",
    "    N = float(sum(count))\n",
    "    for i in range(nclasses):\n",
    "        weight_per_class[i] = N/float(count[i])\n",
    "    weight = [0] * len(images)\n",
    "    for idx, val in enumerate(images):\n",
    "        weight[idx] = weight_per_class[val[1]]\n",
    "    return weight\n",
    "\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "class CustomWeightedRandomSampler(WeightedRandomSampler):\n",
    "    \"\"\"\n",
    "    Custom implementation of WeightedRandomSampler.\n",
    "    WeightedRandomSampler except allows for more than 2^24 samples to be sampled\n",
    "    Args:\n",
    "        *args: Variable length argument list.\n",
    "        **kwargs: Arbitrary keyword arguments.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __iter__(self):\n",
    "        rand_tensor = np.random.choice(range(0, len(self.weights)),\n",
    "                                       size=self.num_samples,\n",
    "                                       p=self.weights.numpy() / torch.sum(self.weights).numpy(),\n",
    "                                       replace=self.replacement)\n",
    "        rand_tensor = torch.from_numpy(rand_tensor)\n",
    "        return iter(rand_tensor.tolist())\n",
    "\n",
    "print(\"loading data...\")\n",
    "\n",
    "model = TandemMod(num_classes=2,vocab_zie=5, embedding_size=4,seq_len=5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss()#.to(device)\n",
    "#predict_result=open(\"rice/results/WT_precit_results.tsv\",\"w\")\n",
    "\n",
    "def predict(model,dataset,cut_off_threshold):\n",
    "\n",
    "    dataloader=torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                           batch_size=4000, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=36,\n",
    "                                           pin_memory=True)\n",
    "\n",
    "    try:\n",
    "\n",
    "        test_acc = 0.\n",
    "        y_test = []\n",
    "        y_pred = []\n",
    "        label_dict={0:\"m5C\",1:\"C\"}\n",
    "\n",
    "        for i,(batch_x, batch_y) in enumerate(dataloader):\n",
    "\n",
    "            signal, kmer, mean, std, intense, dwell,base_quality = batch_x\n",
    "            signal= Variable(signal.to(device)).to(torch.float32)\n",
    "\n",
    "            kmer = Variable(kmer.to(device)).to(torch.long)\n",
    "            mean = Variable(mean.to(device)).to(torch.float32)\n",
    "            std = Variable(std.to(device)).to(torch.float32)\n",
    "            intense = Variable(intense.to(device)).to(torch.float32)\n",
    "            dwell = Variable(dwell.to(device)).to(torch.float32)\n",
    "            base_quality = Variable(base_quality.to(device)).to(torch.float32)\n",
    "            batch_size, features = signal.size()\n",
    "            signal = signal.view(batch_size, 1, features)\n",
    "\n",
    "            out = model(signal, kmer, mean, std, intense, dwell,base_quality )\n",
    "            batch_size, out_channels = out.size()\n",
    "\n",
    "            out = out.view(batch_size, out_channels)\n",
    "            pred = torch.max(out, 1)[1].numpy()\n",
    "\n",
    "            out=torch.softmax(out,dim=1)\n",
    "            probabilities=out.detach().numpy()[:,1]\n",
    "            batch_y=batch_y.detach().numpy()\n",
    "            print(probabilities)\n",
    "            \n",
    "            selected_batch_y=[]\n",
    "            selected_probabilities=[]\n",
    "            for j in range(len(batch_y)):\n",
    "                if probabilities[j]<cut_off_threshold[0] or probabilities[j]>cut_off_threshold[1]:\n",
    "                    selected_batch_y.append(batch_y[j])\n",
    "                    selected_probabilities.append(probabilities[j])\n",
    "            \n",
    "            print(cut_off_threshold[0],len(selected_batch_y))\n",
    "            fpr,tpr,thersholds=roc_curve(selected_batch_y,selected_probabilities)\n",
    "            precision,recall,thersholds=precision_recall_curve(selected_batch_y,selected_probabilities)\n",
    "            \n",
    "            roc_auc=auc(fpr,tpr)\n",
    "            pr_auc=auc(recall,precision)\n",
    "            \n",
    "            return fpr,tpr,precision,recall,roc_auc,pr_auc,probabilities\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        traceback.print_exc()\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Extract feature from signal.')\n",
    "    parser.add_argument('-feature', default='BaseCalled_template',help='Basecall subgroup Nanoraw resquiggle into. Default is BaseCalled_template')\n",
    "    args = parser.parse_args()\n",
    "  \n",
    "    \n",
    "    fprs,tprs,precisions,recalls,normalization_roc,normalization_pr=[],[],[],[],[],[]\n",
    "    \n",
    "    dataset=MyDataset(x_test_median_mad,y_test_median_mad)\n",
    "    \n",
    "    model= torch.load('model/m5C_median_mad.pkl')\n",
    "    fpr,tpr,precision,recall,roc_auc_MMAD,pr_auc_MMAD,probabilities=predict(model,dataset,[0.1,0.9])\n",
    "    fprs.extend(fpr)\n",
    "    tprs.extend(tpr)\n",
    "    precisions.extend(precision)\n",
    "    recalls.extend(recall)\n",
    "    normalization_roc.extend([\"curlcake AUC %.2f\" %roc_auc_MMAD]*len(fpr))\n",
    "    normalization_pr.extend([\"curlcake AUC %.2f\" %pr_auc_MMAD]*len(precision))\n",
    "    \n",
    "    model= torch.load('model/m5C_Os_AD_median_mad_2.21.pkl')\n",
    "    fpr,tpr,precision,recall,roc_auc_MMAD,pr_auc_MMAD,probabilities=predict(model,dataset,[0.1,0.9])\n",
    "    fprs.extend(fpr)\n",
    "    tprs.extend(tpr)\n",
    "    precisions.extend(precision)\n",
    "    recalls.extend(recall)\n",
    "    normalization_roc.extend([\"IVET AUC %.2f\" %roc_auc_MMAD]*len(fpr))\n",
    "    normalization_pr.extend([\"IVET AUC %.2f\" %pr_auc_MMAD]*len(precision))\n",
    "   \n",
    "    black = '#222222'\n",
    "    gray = '#666666'\n",
    "    red = '#FF3333'\n",
    "    green = '#66CC00'\n",
    "    blue = '#3333FF'\n",
    "    purple = '#9933FF'\n",
    "    orange = '#FF8000'\n",
    "    yellow = '#FFFF33'\n",
    "    salmen = \"#FA8072\"\n",
    "    limegreen = '#32CD32'\n",
    "    deepskyblue = '#00AFEE'\n",
    "    c1=\"#F8766D\"\n",
    "    c2=\"#00BA38\"\n",
    "    c3=\"#619CFF\"\n",
    "\n",
    "\n",
    "    \n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    #a=matplotlib.text.Text()\n",
    "    #a.set_family(\"Arial\")\n",
    "    data=pd.DataFrame(dict(fpr=fprs,tpr=tprs,normalization=normalization_roc)) \n",
    "    p1 = (ggplot()\n",
    "            +geom_line(data,aes(x=\"fpr\",y = \"tpr\",group=\"normalization\",color='normalization'))\n",
    "            +geom_line(pd.DataFrame(dict(x=[0,1],y=[0,1])),aes(x=\"x\",y=\"y\"),linetype=\"dashed\",alpha=0.3)\n",
    "            +theme(panel_background=element_rect(fill=gray, alpha=0),\n",
    "                panel_grid_major=element_line(size=0.3, alpha=0.3,color=black),\n",
    "                panel_grid_minor=element_line(size=0.3, alpha=0.3,color=black),\n",
    "                panel_border=element_rect(color=black, size=1),\n",
    "                axis_text=element_text(size=6,family=\"Arial\",color=\"black\"),\n",
    "                axis_title_x=element_text(size=6,family=\"Arial\",color=\"black\"),\n",
    "                axis_title_y=element_text(size=6,family=\"Arial\",color=\"black\"),\n",
    "                plot_title=element_text(margin={'b': 1, 'r': 0, 'units': 'pt'},size=6,family=\"Arial\",color=\"black\"),\n",
    "                figure_size=[1.52,1.33],\n",
    "                legend_title = element_text(size=6), #change legend title font size\n",
    "                legend_text = element_text(size=6),\n",
    "                legend_background=element_rect(size=0.5,alpha=0),\n",
    "                legend_position=(0.60,0.3),\n",
    "                legend_key_size=4) #change legend text font size\n",
    "            +labs(x = \"False positive\", y =\"True positive\")\n",
    "            +guides(color = guide_legend(title = \"Training set\"))\n",
    "            +scale_color_manual(values=[c1,c2])\n",
    "            +ggtitle(\"Test m5C model on ELIGOS dataset\")\n",
    " \n",
    "    )\n",
    "    print(p1)\n",
    "    p1.save('figure/m5C_comparate_with_curlcake_roc.pdf')\n",
    "\n",
    "    data=pd.DataFrame(dict(precision=precisions,recall=recalls,normalization=normalization_pr)) \n",
    "    p2 = (ggplot()\n",
    "            #+geom_line(pd.DataFrame(dict(x=[1,0],y=[0,1])),aes(x=\"x\",y=\"y\"),linetype=\"dashed\")\n",
    "            +geom_line(data,aes(x=\"recall\",y = \"precision\",group=\"normalization\",color='normalization'))\n",
    "\n",
    "            +theme(panel_background=element_rect(fill=gray, alpha=0),\n",
    "                panel_grid_major=element_line(size=0.3, alpha=0.3,color=black),\n",
    "                panel_grid_minor=element_line(size=0.3, alpha=0.3,color=black),\n",
    "                panel_border=element_rect(color=black, size=1),\n",
    "                axis_text=element_text(size=6,family=\"Arial\",color=\"black\"),\n",
    "                axis_title_x=element_text(size=6,family=\"Arial\",color=\"black\"),\n",
    "                axis_title_y=element_text(size=6,family=\"Arial\",color=\"black\"),\n",
    "                plot_title=element_text(margin={'b': 1, 'r': 0, 'units': 'pt'},size=6,family=\"Arial\",color=\"black\"),\n",
    "                figure_size=[1.52,1.33],\n",
    "                legend_title = element_text(size=6), #change legend title font size\n",
    "                legend_text = element_text(size=6),\n",
    "                legend_background=element_rect(size=0.5,alpha=0),\n",
    "                legend_position=(0.45,0.3), \n",
    "                legend_key_size=4) #change legend text font size)\n",
    "            +labs(x = \"Recall\", y =\"Precision\")\n",
    "            +guides(color = guide_legend(title = \"Training set\"))\n",
    "            +scale_color_manual(values=[c1,c2])\n",
    "            +ggtitle(\"Test m5C model on ELIGOS dataset\")\n",
    "            )\n",
    "    print(p2)\n",
    "    p2.save('figure/m5C_comparate_with_curlcake_pr.pdf')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
